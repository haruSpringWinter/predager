from pyspark.sql import DataFrame, SparkSession
import MeCab
from gensim.corpora import Dictionary
from pyspark.ml.linalg import Vectors
from preprocess.preprocessor import shape_df


class EmojiKaomojiCountFeaturizer():

    global_dict = Dictionary()
    spark = None

    def __init__(self, sc):
        self.spark = sc

    def featurize(self, df:DataFrame) -> DataFrame:
        data_list = df.rdd.collect()
        mecab = MeCab.Tagger('-Ochasen')
        label_list = []
        wakati_list = []
        for data in data_list:
            tmp_list = []
            node_list = data[1]
            for node in node_list:
                word = node[0]
                tmp_list.append(word)
            if len(tmp_list) != 0:
                label_list.append(data[0])
                wakati_list.append(tmp_list)

        self.global_dict.add_documents(wakati_list)
        dim = len(self.global_dict)
        vec_list = []
        for wakati in wakati_list:
            vec = [0 for _ in range(dim)]
            for word in wakati:
                vec[self.global_dict.token2id[word]] = 1
            vec_list.append(Vectors.dense(vec))
        zip_list = zip(label_list, vec_list)
        new_df = self.spark.createDataFrame(
            zip_list,
            ("label", "features")
        )
        return new_df

if __name__ == '__main__':
    spark = SparkSession.builder\
        .appName('Spark SQL and DataFrame')\
        .getOrCreate()
    df = spark.createDataFrame(
        [(21, "male", "å‹é”ãŒä½œã£ã¦ãã‚ŒãŸãƒ“ãƒã®ç™½ãƒ‰ãƒ¬ã‚¹å¯æ„›ã™ãã¦ãŸã¾ã‚‰ã‚“ğŸ˜"),
         (30, "female", "ã§ãã‚Œã°ãƒ€ãƒ–ã‚ŠãŸããªã„ãŒåˆæœŸã®æ–¹ã®LRã¯é¿ã‘ãŸã„"),
         (40, "male", "ã ã‹ã‚‰ä¸€ç”Ÿå­¤ç‹¬ã§ã‚‚æ§‹ã‚ã‚“ã‚ˆè¦ªã«ã‚‚ä½œã‚Œã¨è¨€ã‚ã‚Œã¦ã„ã‚‹ã‘ã©"),
         ],
        ("age", "sex", "sentence")
    )
    converted_df = shape_df(spark, df).drop('age')
    oneHot = OneHotFeaturizer(spark)
    result_df = oneHot.featurize(converted_df)
    result_df.show(3)