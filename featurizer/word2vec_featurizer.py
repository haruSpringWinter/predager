import numpy as np
from gensim.models import KeyedVectors
from pyspark.sql import DataFrame, SparkSession
import MeCab

def genVec(data_path, row, wc_list):
    model = KeyedVectors.load_word2vec_format(data_path, binary=True)
    mecab = MeCab.Tagger('-Ochasen')
    cnt = 0
    sum_vec = np.array([])
    result_vec = sum_vec
    node = mecab.parseToNode(row[1])
    vc_list = model.index_to_key
    while node:
        word = node.surface
        word_class = node.feature.split(",")[0]
        if word in vc_list and word_class in wc_list:
            cnt += 1
            if cnt == 1:
                sum_vec = model.get_vector(word).copy()
            else:
                sum_vec += model.get_vector(word)
        node = node.next
    if cnt != 0:
        result_vec = sum_vec / cnt
    return row[0], result_vec.tolist()

def featurize(data_path:str, df:DataFrame, wc_list=None):
    if wc_list is None:
        wc_list = ["åè©", "å½¢å®¹è©", "å‹•è©"]
    return df.rdd.map(lambda x: genVec(data_path, x, wc_list)).toDF(schema=["label", "features"])

if __name__ == '__main__':
    spark = SparkSession.builder\
        .appName('Spark SQL and DataFrame')\
        .getOrCreate()
    df = spark.createDataFrame(
        [(1, "å‹é”ãŒä½œã£ã¦ãã‚ŒãŸãƒ“ãƒã®ç™½ãƒ‰ãƒ¬ã‚¹å¯æ„›ã™ãã¦ãŸã¾ã‚‰ã‚“ğŸ˜"),
         (0, "ã§ãã‚Œã°ãƒ€ãƒ–ã‚ŠãŸããªã„ãŒåˆæœŸã®æ–¹ã®LRã¯é¿ã‘ãŸã„"),
         (0, "ã ã‹ã‚‰ä¸€ç”Ÿå­¤ç‹¬ã§ã‚‚æ§‹ã‚ã‚“ã‚ˆè¦ªã«ã‚‚ä½œã‚Œã¨è¨€ã‚ã‚Œã¦ã„ã‚‹ã‘ã©"),
         ],
        ("label", "sentence")
    )
    datapath = "../param/word2vec/entity_vector/entity_vector.model.bin"
    df = featurize(datapath, df)
    df.show(3)